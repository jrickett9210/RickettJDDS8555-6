{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "    black  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "boston = pd.read_csv(\"boston.csv\")\n",
    "\n",
    "print(boston.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 22.7640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = boston.drop(\"medv\", axis=1)\n",
    "y = boston[\"medv\"]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8555)\n",
    "\n",
    "# Linear Regression \n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions \n",
    "y_pred_lin = lin_model.predict(X_test)\n",
    "\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "print(f\"Linear Regression MSE: {mse_lin:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Categorical: 1 if medv above median, else 0\n",
    "y_binary = (boston[\"medv\"] > boston[\"medv\"].median()).astype(int)\n",
    "\n",
    "\n",
    "X = boston.drop(\"medv\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=8555)\n",
    "\n",
    "# Logistic Regression \n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting MSE: 6.2044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = boston.drop(\"medv\", axis=1)\n",
    "y = boston[\"medv\"]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8555)\n",
    "\n",
    "# Boosting Model\n",
    "boost_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=8555)\n",
    "boost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions \n",
    "y_pred_boost = boost_model.predict(X_test)\n",
    "\n",
    "\n",
    "mse_boost = mean_squared_error(y_test, y_pred_boost)\n",
    "print(f\"Boosting MSE: {mse_boost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging MSE: 7.5906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bag Model\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=8555)\n",
    "bag_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_bag = bag_model.predict(X_test)\n",
    "\n",
    "mse_bag = mean_squared_error(y_test, y_pred_bag)\n",
    "print(f\"Bagging MSE: {mse_bag:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 7.9702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random Forest \n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=8555)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART Model:\n",
    "\n",
    "NOTE: was unable to get BART to work in python. However, I used R to produce a BART model with an MSE of 10.81. \n",
    "\n",
    "R CODE BELOW\n",
    "\n",
    "library(BayesTree)\n",
    "\n",
    "library(BART)\n",
    "\n",
    "boston<-read.csv(\"boston.csv\")\n",
    "\n",
    "\n",
    "\\# Split training and testing data\n",
    "\n",
    "set.seed(8555)\n",
    "\n",
    "sample_index <- sample(1:nrow(boston), 0.8 * nrow(boston))\n",
    "\n",
    "train_data <- boston[sample_index, ]\n",
    "\n",
    "test_data <- boston[-sample_index, ]\n",
    "\n",
    "\n",
    "X_train <- train_data[, !names(train_data) %in% c(\"medv\")]\n",
    "\n",
    "y_train <- train_data$medv\n",
    "\n",
    "X_test <- test_data[, !names(test_data) %in% c(\"medv\")]\n",
    "\n",
    "y_test <- test_data$medv\n",
    "\n",
    "\\# Fit BART\n",
    "\n",
    "bart_model <- bart(x.train = X_train,\n",
    "                   y.train = y_train,\n",
    "                   x.test = X_test,\n",
    "                   verbose = FALSE)\n",
    "\n",
    "\\# predictions\n",
    "\n",
    "y_pred <- bart_model$yhat.test.mean\n",
    "\n",
    "\\# Calculate Mean Squared Error\n",
    "\n",
    "mse <- mean((y_test - y_pred)^2)\n",
    "\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
